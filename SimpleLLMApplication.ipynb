{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cdfd13f",
   "metadata": {},
   "source": [
    "<h1>Simple LLM Application <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b11eaff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have followed the tutorial: https://python.langchain.com/v0.2/docs/tutorials/llm_chain/\n",
    "# The full tutorial list is below, my study plan is to follow these tutorials: https://python.langchain.com/v0.2/docs/tutorials/\n",
    "# Introduction page: https://python.langchain.com/v0.2/docs/introduction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40fc78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optionally create a virtual environment guide is here:\n",
    "# https://www.geeksforgeeks.org/using-jupyter-notebook-in-virtual-environment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6463313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To install langchain:\n",
    "\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b97a553f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: Langchain-core== 0.2.9\n"
     ]
    }
   ],
   "source": [
    "#Set environment variables:\n",
    "\n",
    "#%env LANGCHAIN_TRACING_V2=\"true\"\n",
    "#%env LANGCHAIN_API_KEY=\"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\"\n",
    "#%env Langchain-core == 0.2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90101e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "transformers 4.24.0 requires tokenizers!=0.11.3,<0.14,>=0.11.1, but you have tokenizers 0.20.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#I chose openai but they started charging for API use, so I tried huggingface since its the only 1 that seems 2 be free:\n",
    "\n",
    "#Unlike openai, huggingface doesnt require API\n",
    "#So we setup the huggingface below:\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install -qU langchain-cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a1fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install langchain transformers\n",
    "#!{sys.executable} -m pip install langchain_core\n",
    "#!{sys.executable} -m pip install sentencepiece\n",
    "\n",
    "\n",
    "# I DONT UNDERSTAND THE INNER WORKINGS OF THIS PART SINCE ITS DIFFERENT FROM THE TUTORIAL\n",
    "from transformers import pipeline\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "import sentencepiece\n",
    "\n",
    "\n",
    "# Load the Hugging Face translation pipeline\n",
    "translation_pipeline = pipeline(\"translation_en_to_it\", model=\"Helsinki-NLP/opus-mt-en-it\")\n",
    "\n",
    "class HuggingFaceTranslator:\n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "\n",
    "    def invoke(self, messages):\n",
    "        # Extract content from the HumanMessage\n",
    "        human_message_content = next((msg.content for msg in messages if isinstance(msg, HumanMessage)), None)\n",
    "        if human_message_content is None:\n",
    "            raise ValueError(\"No HumanMessage found in messages.\")\n",
    "\n",
    "        # Translate the content using the Hugging Face pipeline\n",
    "        translation = self.pipeline(human_message_content)\n",
    "        translated_text = translation[0]['translation_text']\n",
    "\n",
    "        # Return an AIMessage with the translated content\n",
    "        return AIMessage(content=translated_text)\n",
    "\n",
    "# Instantiate your custom translator with the Hugging Face pipeline\n",
    "model = HuggingFaceTranslator(translation_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678b0b80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
